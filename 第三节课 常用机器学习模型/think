Thinking1：什么是监督学习，无监督学习，半监督学习
监督学习：就是有标签的学习，即不仅需要把数据输入给计算机，还要把分类的结果（标签）输入给计算机进行分析，
来对新的数据进行预测分类。函数的输出可以个一个连续的值（回归分析）或者分类标签分类任务。
监督学习的常用场景，分类问题和回归问题。常见算法有逻辑回归（Logistic Regression）
和反向传递神经网络（Back Propagation Neural Network）

无监督学习：没有标签的学习，已知数据没有标签，计算机会按照一定偏好训练，将所有数据映射到不同的分类中。
计算机学习后，再丢给它新的数据，它也能计算出该数据导致各种结果的概率，给你一个最接近正确的结果。
在无监督学习中，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。常见的应用场景包括关联规则的学习以及聚类等。
常见的应用场景包括关联规则的学习以及聚类等。常见算法包括 Apriori 算法以及 k-Means 算法。
什么时候用聚类，缺乏足够的先验知识，人工打标签成本高

半监督学习：其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常远远大于有标签数据数量。
隐藏在半监督学习下的基本规律在于：数据的分布必然不是完全随机的，通过一些有标签数据的局部特征，
以及更多没标签数据的整体分布，就可以得到可以接受甚至是非常好的分类结果。

Thinking2：K-means中的k值如何选取
可以利用手肘法，手肘法的核心是sse（误差平方和）
手肘法的核心思想是，随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，误差平法差和下降


Thinking3：随机森林采用了bagging集成学习，bagging指的是什么
对数据进行自助采样法，对结果进行简单投票法。
对于给定的包含m个样本的数据集，随机选择一个样本放入采样集中，
再把该样本放回初始数据集，使得下次采样仍有可能被选中。这样选择的样本有的在采样集里面重复出现，
有的则从未出现。分类任务使用简单投票法；对分类任务使用简单平均法；
若分类投票出现相同的票数情况，则随机选择一个。


Thinking4：主动学习和半监督学习的区别是什么
主动学习的“主动”，指的是主动提出标注请求，
也就是说，还是需要一个外在的能够对其请求进行标注的实体(通常就是相关领域人员)，
即主动学习是交互进行的。而半监督学习，特指的是学习算法不需要人工的干预，基于自身对未标记数据加以利用。